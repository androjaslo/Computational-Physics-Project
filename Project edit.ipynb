{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYjWoRDj1kWG"
   },
   "source": [
    "# HEART RATE ESTIMATION\n",
    "\n",
    "Seismocardiography([SCG](https://www.ncbi.nlm.nih.gov/pubmed/24111357)) is a very promising technique to measure Heart Rate (HR) and Respiratory Rate (RR) with the detector positioned above sternum. It is generally based on accelerometer and gyroscope readings or a combination of them.\n",
    "\n",
    "Ballistocardiography([BCG](https://en.wikipedia.org/wiki/Ballistocardiography)) is an another technique to estimate heart and respiratory rate with combination of both accelerometer and gyroscope. It is an indirect evaluation of HR and RR since the contact between the device and the body of the subject is not required (e.g., accelerometer platform mounted under the slats of the bed).   \n",
    "  \n",
    "MuSe(Multi-Sensor miniaturized, low-power, wireless [IMU](https://en.wikipedia.org/wiki/Inertial_measurement_unit)) is an Inertial Measurement Unit (IMU) provide by [221e](https://www.221e.com). In the context of this project, It allows to record the inertial data necessary for the estimation of SCG and BCG.\n",
    "\n",
    "The goal of this assignment is to estimate the heart rate of an healthy subject, given linear acceleration and angular velocity measurements recorded by using the aforementioned MuSe platform.\n",
    "The study must be performed on two datasets: the first is the compulsory one (**center_sternum.txt**) while the second is left at the discretion of the group, among those made available for the assignment.\n",
    "\n",
    "**N.B: Remember that normal beat is around [40-100] bpm.**\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The data is provided in .txt file. During this study two healthy subjects were involved with their informed consent. The first dataset was recorded on one subject, while all the other datasets were recorded on the second subject.\n",
    "\n",
    "This is the first mandatory file:\n",
    "\n",
    "* **center_sternum.txt**: MuSe placed on the center of the sternum. The subject was lying supine on his left and right side, respectively.\n",
    "\n",
    "\n",
    "Choose one of the following files in order to complete the task.\n",
    "\n",
    "1. **1_Stave_supine_static.txt**: Sensor placed on a bed stave, under the mattress at the level of the chest. The subject was lying supine on his left and right side.\n",
    "* **2_Mattress_supine.txt**: Sensor placed on the mattress, near one corner but not under the pillow. The subject laid in the same position as above.\n",
    "* **3_Subject_sitting_chair.txt**: Sensor placed on the desk: the subject, sitting on a chair, leaned forearms and hands on the desk.\n",
    "* **4_Chest_sweater.txt**: Sensor placed on the subject chest directly on a sweater.\n",
    "* **5_Under_chair.txt**: Subject sitting on a chair, sensor placed under the seat of the chair.\n",
    "\n",
    "All .txt files give 16 columns index, in particular:\n",
    "\n",
    "* Log Freq stands for the acquisition  in Hz (i.e., sampling interval is constant).\n",
    "* AccX, AccY, AccZ are the measured magnitude of linear acceleration along each axis.\n",
    "* GyroX, GyroY, GyroZ are the measured magnitude of angular velocity along each axis.\n",
    "* MagnX, MagnY, MagnZ are the measured magnitude of magnetic field along each axis.\n",
    "* qw, qi, qj, qk are the quaternion components, representing the spatial orientation of the Muse system.\n",
    "\n",
    "Each dataset includes, in addition to the data, one file containing the adopted configuration of the MuSe(**README1.txt** for the first measurement, and in **README_5.txt** for the other measurement).\n",
    "\n",
    "\n",
    "\n",
    "## Assignment\n",
    "\n",
    "\n",
    "\n",
    "1. Data preparation:\n",
    "\n",
    "    1.1. Load the txt file and select only the columns you are interesting in, in order to do a complete data analysis (e.g. Log Freq, AccX, ... )\n",
    "    \n",
    "    1.2. Plot selected data in function of time and choose a properly time window over which to perform the analysis. Pay attention on time rappresentation and the measurament unit.\n",
    "    \n",
    "    1.3. In order to make an appropiate work, decide if take care about some particular axis or some combination of them as well as derived features for the next step of the task. Motivate your choice.  \n",
    "\n",
    "\n",
    "    \n",
    "2. Time and frequency analysis:\n",
    "\n",
    "    2.1. Statistical analysis: provide a statistical description of the chosen dataset. Statistical descriptors includes for example mean, median, variance, standard deviation, 25th and 75th percentiles, and correlation coefficients. Investigate what could be the most interesting descriptors for this type of data, motivating the choices.\n",
    "    \n",
    "    2.2. Fourier Analysis: Perform a frequency analysis of the data. Look at the spectrum and explain what you see. Use this step in order to properly design the filters in the following step.\n",
    "\n",
    "\n",
    "\n",
    "3. Filter:\n",
    "    \n",
    "    Implement your own filter, trying to extrapolate heart rate signal. Hint:\n",
    "    \n",
    "    (a) Directly from Fourier Analysis, antitrasform data looking for the most interesting frequency band.\n",
    "    \n",
    "    (b) Choose the appropriate Lowpass/Bandpass/Highpass filter.\n",
    "    \n",
    "    (c) Wavelet trasform (a powerfull instrument that make a time and frequency analysis of signal).\n",
    "    \n",
    "    (d) Find another method by yourselves.\n",
    "    \n",
    "    Motivate your choice.\n",
    "    \n",
    "    \n",
    "4. Metrics:\n",
    "\n",
    "    4.1. Heart Beat Per Minute(BPM): extrapolate BPM, make an histogram of the result. Does it follow a partiular distribution?\n",
    "    \n",
    "    4.2. Heart Rate Variability(HRV): extrapolate HRV, explain why this parameter is important, and plot the results.\n",
    "\n",
    "\n",
    "\n",
    "5. (OPTIONAL) Algorithm: Elaborate a simple algorithm to extrapolate heart beat even when filter failed (e.g. look at particular threshold...).  \n",
    "\n",
    "\n",
    "\n",
    "6. Conclusion:\n",
    "\n",
    "    Summarise the obtained results, in particular making a comparison between the two files analysed. Highlight limitation and critical issues encountered during the work, motivating the most relevant contribution given by your solution.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**N.B: Indicate the contribution, to achieving the result, of each member of the group.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwaJuPlX1y4u"
   },
   "source": [
    "#First approach to datasets in assigment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nhCGw2p3RNK"
   },
   "source": [
    "Here, we are making a list of the libraries we consider necesary for the development of the project analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYQHM00u3bdX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEVrVKjy14yp"
   },
   "source": [
    "So, as the mandatory file has to be loaded, we will keep it appart, for the other ones, as we think is fundamental to take a look over the data, we ar going to get info and basic review over the multiple datasets, and maybe a superficial search of correlation between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2470,
     "status": "ok",
     "timestamp": 1771602552087,
     "user": {
      "displayName": "Gabriela Landinez",
      "userId": "02977943320447332610"
     },
     "user_tz": -60
    },
    "id": "WNJzgEU_1kWI",
    "outputId": "045eae97-58a8-4efe-94ed-e51655e15315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvyGOKEa2tei"
   },
   "outputs": [],
   "source": [
    "path='/content/drive/MyDrive/PADOVA/Computational physics lab/Project'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-BWO-ZhjyWo"
   },
   "source": [
    "#Dictionary of variables for reference\n",
    "cs :  Main dataset of center_sternum . the manatory one\n",
    "\n",
    "\n",
    "one: Df ONE Stave supine static\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "error",
     "timestamp": 1771602552128,
     "user": {
      "displayName": "Gabriela Landinez",
      "userId": "02977943320447332610"
     },
     "user_tz": -60
    },
    "id": "XNBUjx1C2sDz",
    "outputId": "05e07b66-ad03-484a-8463-c7febba119cd"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/PADOVA/Computational physics lab/Project/center_sternum.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1965490652.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/center_sternum.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/PADOVA/Computational physics lab/Project/center_sternum.txt'"
     ]
    }
   ],
   "source": [
    "cs=pd.read_csv(path+'/center_sternum.txt',sep='\\t')\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EyKQuRL2q_S"
   },
   "outputs": [],
   "source": [
    "cs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV3PRLgv5kvi"
   },
   "source": [
    "Plots of acceleration in axis and angular veloxity in axis ( gyroscope measures velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTgVSFOi8v9L"
   },
   "outputs": [],
   "source": [
    "\n",
    "x=cs['Timestamp']\n",
    "x=np.arange(0,len(x))\n",
    "plt.plot(x, cs['AccX'],label='Acceleration in X')\n",
    "plt.plot(x, cs['AccY'],label='Acceleration in Y')\n",
    "plt.plot(x,cs['AccZ'],label='Acceleration in Z')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Acceleration (au)')\n",
    "plt.legend()\n",
    "plt.title('Acceleration in axis for \"center sternum MuSe\"')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,cs['GyroX'],label='Angular velocity in X')\n",
    "plt.plot(x,cs['GyroY'],label='Angular velocity in Y')\n",
    "plt.plot(x,cs['GyroZ'],label='Angular velocity in Z')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Angular velocity (au)')\n",
    "plt.legend()\n",
    "plt.title('Angular velocity in axis for \"center sternum MuSe\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtRjFwSG21uy"
   },
   "source": [
    "In the literature is recommended to calculate the magnitude of the acceleration, so here we have  $$a= \\sqrt{ax^2 + ay^2 +az^2}$$\n",
    "\n",
    "Furthermore, the same is recommended to the gyroscope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgtXHd3M31Pd"
   },
   "outputs": [],
   "source": [
    "cs['MagAcc']=np.sqrt(cs['AccX']**2 + cs['AccY']**2 + cs['AccZ']**2)\n",
    "cs['MagGyro']=np.sqrt(cs['GyroX']**2+cs['GyroY']**2+cs['GyroZ']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ywq83uQ21bF"
   },
   "outputs": [],
   "source": [
    "plt.plot(x,cs['MagAcc'],label='Magnitude of acceleration',color='g')\n",
    "plt.title('Magitude of Acceleration')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,cs['MagGyro'],label='Magnitude of angular velocity',color='g')\n",
    "plt.title('Magnitude of angular velocity')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAL99g31-kN8"
   },
   "source": [
    "#Exploration over the first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6-WOrW86CKz"
   },
   "outputs": [],
   "source": [
    "one=pd.read_csv(path+'/1_Stave_supine_static.txt',sep='\\t')\n",
    "one.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdmSnsxUe7iy"
   },
   "source": [
    "Here i make an adjustment over the data because we on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUbzQxzt_Oeo"
   },
   "outputs": [],
   "source": [
    "one1=one.head(2500)\n",
    "cs1=cs.head(2500)\n",
    "#one1=one.tail(2500)\n",
    "#cs1=cs.tail(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrXDaUJC79Oq"
   },
   "outputs": [],
   "source": [
    "one['Log Freq'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGkq5VaD-SJU"
   },
   "source": [
    "Comparative over the first measurements , where the data looks relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0-QeeMd56UV"
   },
   "outputs": [],
   "source": [
    "x=one1['Timestamp']\n",
    "x=np.arange(0,len(x))\n",
    "plt.plot(x, one1['AccX'],label='Acceleration in X ONE')\n",
    "#plt.plot(x, one1['AccY'],label='Acceleration in Y ONE')\n",
    "#plt.plot(x,one1['AccZ'],label='Acceleration in Z ONE')\n",
    "\n",
    "plt.plot(x, cs1['AccX'],label='Acceleration in X')\n",
    "#plt.plot(x, cs1['AccY'],label='Acceleration in Y')\n",
    "#plt.plot(x,cs1['AccZ'],label='Acceleration in Z')\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Acceleration (au)')\n",
    "plt.legend()\n",
    "plt.title('Acceleration in axis for \"Stave_supine_static\"')\n",
    "\"\"\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,one1['GyroX'],label='Angular velocity in X ONE')\n",
    "plt.plot(x,one1['GyroY'],label='Angular velocity in Y ONE')\n",
    "plt.plot(x,one1['GyroZ'],label='Angular velocity in Z ONE')\n",
    "\n",
    "plt.plot(x,cs1['GyroX'],label='Angular velocity in X')\n",
    "plt.plot(x,cs1['GyroY'],label='Angular velocity in Y')\n",
    "plt.plot(x,cs1['GyroZ'],label='Angular velocity in Z')\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Angular velocity (au)')\n",
    "plt.legend()\n",
    "plt.title('Angular velocity in axis for \"Stave_supine_static\"')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCvTBl9liVmu"
   },
   "source": [
    "#Statistical analisys\n",
    "Using the description of the DATASETS, we can now take a look over the important statistical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJKGexSO8Oz_"
   },
   "outputs": [],
   "source": [
    "cs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dlABq-lMjrWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polina\n"
     ]
    }
   ],
   "source": [
    "print(\"polina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
